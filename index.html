<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.png"> <title>Nikola</title> <header> <div class=blog-name ><a href="/">Nikola Janjušević</a></div> <nav> <ul> <li><a href="/teaching">Teaching</a> <li><a href="/publications">Publications</a> <li><a href="/notes">Notes</a> <li><a href="/assets/janjusevic_cv.pdf">CV</a> </ul> <img src="/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content ><h2 id=about_me ><a href="#about_me" class=header-anchor >About me</a></h2> <div class=row ><div class=container ><img class=left  id=profpic src="assets/headshot1.jpg" onmouseover="this.src='assets/headshotQ.jpg';" onmouseout="this.src='assets/headshot1.jpg';" > <p>Hello. My name is Nikola Janjušević. I am a Post Doctoral Researcher at the NYU Langone Health Department of Radiology. I earned my Ph.D. in Electrical Engineering from <em>New York University</em> under the advisory of Professor Yao Wang, <a href="https://wp.nyu.edu/videolab/">NYU VideoLab</a>, in 2024. I received my Bachelors in Electrical Engineering from <em>The Cooper Union for Advancement of Science and Art</em> in 2019. </p> <p>My current interests are in <em>interpretable deep-learning</em> models for solving noisy MRI reconstruction problems without ground-truth data. My background is in <em>signal-processing</em>, <em>non-smooth convex optimization</em>, and deep-learning. Outside of academia, I go climbing, biking, and skateboarding with my friends.</p> <p>Email me at <strong>nikola at nyu dot edu</strong>.</p></div></div> <h2 id=updates ><a href="#updates" class=header-anchor >Updates</a></h2> <ul> <li><p>&#91;April 2025&#93; Amir and I will be at IEEE MIPR 2025 to give our Tutorial, <a href="https://sites.google.com/view/mipr-2025/tutorial?authuser&#61;0#h.nazvd3zhbs51"><em>Directly Parameterized Neural Network Construction for Generalization and Robustness</em></a>, August 6th-8th San Jose CA, 2025.</p> <li><p>&#91;April 2025&#93; I&#39;ll be giving an IEEE webinar with Dr. Amirhoussein Khalilian-Gourtani, <a href="https://signalprocessingsociety.org/blog/sps-webinar-directly-parameterized-neural-network-construction-generalization-and-robustness"><em>SPS Webinar: Directly Parameterized Neural Network Construction for Generalization and Robustness in Imaging Inverse Problems</em></a>, July 17th 11:30am EST. Register with the link&#33;</p> <li><p>&#91;April 2025&#93; <a href="https://arxiv.org/abs/2504.17698"><em>Self-Supervised Noise Adaptive MRI Denoising via Repetition to Repetition &#40;Rep2Rep&#41; Learning</em></a> preprint available.</p> <li><p>&#91;February 2025&#93; <a href="https://ieeexplore.ieee.org/document/10874214"><em>GroupCDL: Interpretable Denoising and Compressed Sensing MRI via Learned Group-Sparsity and Circulant Attention</em></a> published in IEEE Transactions on Computational Imaging.</p> <li><p>&#91;January 2025&#93; I&#39;m going to <a href="https://www.ismrm.org/25m/">ISMRM 2025</a> in Hawaii this May to poster present two abstracts&#33;</p> <li><p>&#91;December 2024&#93; <em>Learned Primal Dual Splitting for Self-Supervised Noise-Adaptive MRI Reconstruction</em> accepted in <a href="https://biomedicalimaging.org/2025/">ISBI 2025</a>.</p> <li><p>&#91;September 2024&#93; Joined NYU Langone Health&#33;</p> <li><p>&#91;August 2024&#93; Successfully defended my thesis and finished my thesis&#33;</p> <li><p>&#91;May 27th 2024&#93; Gave a talk in Belgrade: <a href="https://www.vos.edu.rs/strategija-razvoja-vestacke-inteligencije-vest28-05-2024/"><em>Strategija Razvoja Veštačke Inteligencije Kod Nas</em>/<em>An Artificial Inteligence Strategy for Serbia</em></a>, Eduka Institute of Organizational Business.</p> </ul> <div class=container ><center> <img id=updatepictall src="assets/fos24/fos24_tall.jpg" > <img id=updatepic src="assets/fos24/fos24_wide.jpg" > </center></div> <ul> <li><p>&#91;May 9th 2024&#93; Presented at <a href="https://www.ismrm.org/24m/">ISMRM 2024</a> in Singapore&#33;</p> <ul> <li><p><em>&quot;Advanced Deep Learning Denoising for Accelerated 0.55T Prostate MRI&quot;</em> &#40;Power-Pitch &#43; Digital Poster Presentation&#41;</p> <li><p><em>&quot;SNAC-DL: Self-Supervised Network for Adaptive Convolutional Dictionary Learning of MRI Denoising&quot;</em> &#40;Digital Poster Presentation&#41;</p> </ul> </ul> <div class=container ><center> <img id=updatepic src="assets/ismrm24/ismrm24_presenting.jpg" > <img id=updatepictall src="assets/ismrm24/ismrm24_biking.jpg" > </center></div> <h2 id=recent_blog_posts ><a href="#recent_blog_posts" class=header-anchor >Recent blog posts</a></h2> <ul> <li><p><strong><a href="/blog/chain_rule/">&#40;Apr 12 2023&#41; On using the multi-dimensional chain-rule correctly.</a></strong></p> </ul> <p>TLDR: employing the multi-dimensional chain-rule means writing matrix-multiplication. ...</p> <ul> <li><p><strong><a href="/blog/conv/">&#40;Dec 11 2022&#41; How to think of Conv-Layers in Neural Networks</a></strong></p> </ul> <p>Convolutional Neural Networks&#39; building blocks aren&#39;t just performing the convolution you learned in DSP. In my opinion, the best way to think of these layers is as a channel-wise matrix-vector multiplication of convolutions. <img alt="convolution blocks" src="/assets/conv/conv_blocks.svg" style="width:50%" class=center  /> ...</p> <ul> <li><p><strong><a href="/blog/small_nets/">&#40;Dec 11 2022&#41; How do black-box denoisers perform at the lower parameter-count regime, anyway?</a></strong></p> </ul> <p>So-called interpretably constructed deep neural networks often sell their methods by showing near state-of-the-art performance for only a fraction of the parameter count of black-box networks. However, can we consider these fair comparisons when the number of learned parameter counts are not matched? ...</p> <ul> <li><p><strong><a href="/blog/julia_tvd/">&#40;Jun 5 2021&#41; Introduction to Julia by TV denoising</a></strong></p> </ul> <p>A walkthrough of implementing Total Variation color image denoising in the Julia programming language, starring Fabio and Masa. <img src="/assets/tvd/exfabio.png" alt="" /> ...</p> <ul> <li><p><strong><a href="/blog/arxivmv/">&#40;Oct 25 2020&#41; Staying organized while doing research &#40;arxivmv&#41;.</a></strong></p> </ul> <p>I often find my downloads folder filling up with tons of research papers with nondescript &#40;ID&#41; names, such as &quot;1909.05742.pdf&quot;. Keeping these PDFs open allows me to keep track of them, but once I close those windows they seem as good as lost. To remedy this, I&#39;ve written a short Python script employing a <a href="https://github.com/lukasschwab/arxiv.py">wrapper for the arXiv.org API</a>. ...</p> <ul> <li><p><strong><a href="/blog/understanding-ista/">&#40;Feb 29 2020&#41; Understanding ISTA as a Fixed-Point Iteration</a></strong></p> </ul> <p>The iterative soft thresholding algorithm is one of the simplest algorithms for sparse coding &#40;in this case, solving the basis-pursuit denoising functional&#41;. Understanding its derivation as a special case of the Proximal Gradient Method is a great introduction into the world of <strong>proximal methods</strong>. ...</p> <ul> <li><p><strong><a href="/blog/auto-reload-latex/">&#40;Jan 3 2020&#41; My auto-reload setup for writing LATEX documents in VIM</a></strong></p> </ul> <p>Zathura &#43; latexmk -&gt; :&#41;. Latest update: 17th January 2021. ...</p> <div class=page-foot > <div class=copyright > <!--<a href="https://github.com/nikopj">GitHub</a> <br> --> &copy; <a href="https://github.com/nikopj">Nikola Janjušević</a>. Last modified: 0001-01-01. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> + <a href="https://julialang.org">Julia</a>. </div> </div> </div>