<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.png"> <title>The Convolutional Dictionary Learning Network</title> <header> <div class=blog-name ><a href="/">Nikola Janjušević</a></div> <nav> <ul> <li><a href="/teaching">Teaching</a> <li><a href="/publications">Publications</a> <li><a href="/notes">Notes</a> <li><a href="/assets/resume.pdf">Résumé</a> </ul> <img src="/assets/hamburger.svg" id=menu-icon > </nav> </header> <div class=franklin-content > <h1 id=title ><a href="#title" class=header-anchor >The Convolutional Dictionary Learning Network</a></h1> <figure style="text-align:center;"> <img src="/assets/dcdl/cdlnet_blockdiagram2.png" style="padding:0; width:100%" alt=" CDLNet Block Diagram."/> <figcaption> CDLNet Block Diagram.</figcaption> </figure> <div class=franklin-toc ><ol><li><a href="#project_overview">Project Overview</a><li><a href="#generalization_in_denoising">Generalization in Denoising</a><li><a href="#gabor_is_enough">Gabor is Enough&#33;</a></ol></div> <h3 id=latest_updates ><a href="#latest_updates" class=header-anchor >Latest Updates:</a></h3> <ul> <li><p>May 2022:</p> <ul> <li><p><a href="https://arxiv.org/abs/2204.11146"><em>&quot;Gabor is Enough&quot;</em></a> accepted into <a href="https://2022.ivmsp.org/">IVMSP 2022</a>.</p> <li><p>CDLNet &#43; GDLNet PyTorch code publicly available <a href="https://github.com/nikopj/CDLNet-OJSP">here</a></p> </ul> <li><p>April 2022: </p> <ul> <li><p><a href="https://ieeexplore.ieee.org/document/9769957"><em>CDLNet</em></a> accepted into the <u>IEEE Open Journal of Signal Processing</u>&#33;</p> <li><p>Preprint published: <a href="https://arxiv.org/abs/2204.11146"><em>&quot;Gabor is Enough: Interpretable Deep Denoising with a Gabor Synthesis Dictionary Prior&quot;</em></a>. </p> </ul> </ul> <h2 id=project_overview ><a href="#project_overview" class=header-anchor >Project Overview</a></h2> <p>Sparse representation is a proven and powerful prior for natural images and restoration tasks &#40;such as denoising, deblurring, in-painting, etc.&#41; involving them. More than simply finding these representations, learning an over-complete dictionary for sparse signal representation from degraded signals have been shown to be effective models. Furthermore, the convolutional dictionary learning &#40;CDL&#41; model seeks to represent the global signal via a translated local dictionary. This offers a more holistic approach for natural image representation compared to inherently suboptimal patch-processing methods. The dictionary learning problem is traditionally solved by iteratively compute spare-codes &#40;representations&#41; for a fixed dictionary, and subsequently updating the dictionary accordingly. </p> <p>In this project, <strong>we explore an interpretable Deep Learning architecture for image restoration based on an unrolled CDL model</strong>. More specifically, we leverage the LISTA framework to obtain approximate convolutional sparse codes, followed by a synthesis from a convolutional dictionary. We call this architecture <strong>CDLNet</strong>. The network is trained in a task-driven fashion, amenable to any linear inverse-problem. We believe that interpretable network construction will yield greater insight and novel capabilities.</p> <h3 id=participants ><a href="#participants" class=header-anchor >Participants</a></h3> <ul> <li><p>Yao Wang, Advising Professor, <a href="https://wp.nyu.edu/videolab/">Lab Page</a></p> <li><p><a href="https://nikopj.github.io">Nikola Janjušević</a>, Ph.D. student</p> <li><p><a href="https://amirhkhalilian.github.io/">Amir Khalilian</a>, Ph.D. student</p> </ul> <h2 id=generalization_in_denoising ><a href="#generalization_in_denoising" class=header-anchor >Generalization in Denoising</a></h2> <p>The derivation of the CDLNet architecture allows us to understand the subband thresholds, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>τ</mi><mrow><mo stretchy=false >(</mo><mi>k</mi><mo stretchy=false >)</mo></mrow></msup><mo>∈</mo><msubsup><mi mathvariant=double-struck >R</mi><mo>+</mo><mi>M</mi></msubsup></mrow><annotation encoding="application/x-tex">\tau^{(k)} \in \mathbb R_+^M</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.9270999999999999em;vertical-align:-0.0391em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8879999999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.146662em;vertical-align:-0.305331em;"></span><span class=mord ><span class="mord mathbb">R</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8413309999999999em;"><span style="top:-2.4530000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">M</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.305331em;"><span></span></span></span></span></span></span></span></span></span>, of the soft-thresholding operator as implicitly being a function of the input noise-level <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span>. We thus propose an affine parameterization,</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><msup><mi>τ</mi><mrow><mo stretchy=false >(</mo><mi>k</mi><mo stretchy=false >)</mo></mrow></msup><mo>=</mo><msubsup><mi>τ</mi><mn>0</mn><mrow><mo stretchy=false >(</mo><mi>k</mi><mo stretchy=false >)</mo></mrow></msubsup><mo>+</mo><msubsup><mi>τ</mi><mn>1</mn><mrow><mo stretchy=false >(</mo><mi>k</mi><mo stretchy=false >)</mo></mrow></msubsup><mi>σ</mi></mrow><annotation encoding="application/x-tex"> \tau^{(k)} = \tau_0^{(k)} + \tau_1^{(k)}\sigma </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.938em;vertical-align:0em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.311108em;vertical-align:-0.266308em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.0448em;"><span style="top:-2.433692em;margin-left:-0.1132em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.266308em;"><span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1.311108em;vertical-align:-0.266308em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.1132em;">τ</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.0448em;"><span style="top:-2.433692em;margin-left:-0.1132em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.2198em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mclose mtight">)</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.266308em;"><span></span></span></span></span></span></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span></span> <p>to <em>explicitly model noise-level adaptivity within each layer of the network</em>. This is in stark contrast to the <em>implicitly defined noise-level adaptivity of common black-box neural networks</em>, which either account for noise only via training on a noise range &#40;ex. DnCNN&#41;, or additionally presented the estimated input noise-level as an input to the network &#40;ex. FFDNet&#41;. As shown in the figures below, CDLNet&#39;s explicitly defined noise-level adaptivity allows for near-perfect generalization outside its training range, whereas the black box models either fail or introduce artifacts.</p> <p> <figure style="text-align:center;"> <img src="/assets/dcdl/gray_generalize_plot.png" style="padding:0; width:65%" alt=" CDLNet is able to generalize outside its training noise-level range, whereas black-box neural networks fail."/> <figcaption> CDLNet is able to generalize outside its training noise-level range, whereas black-box neural networks fail.</figcaption> </figure> <figure style="text-align:center;"> <img src="/assets/dcdl/gray_visual.png" style="padding:0; width:100%" alt=" "/> <figcaption> </figcaption> </figure> </p> <p>This generalization characteristic is further demonstrated for the CDLNet architecture extended to color image denoising, joint-denoising-and-demosaicing, and unsupervised learning of denoising.</p> <h3 id=joint_denoising_and_demosaicing ><a href="#joint_denoising_and_demosaicing" class=header-anchor >Joint Denoising and Demosaicing</a></h3> <p>CDLNet extended to the JDD task is able to achieve state-of-the-art results with a single model, out-performing black box neural networks. <figure style="text-align:center;"> <img src="/assets/dcdl/JDD_table.png" style="padding:0; width:90%" alt=" PSNR comparison against state-of-the-art JDD models on the Urban100/MIT moire datasets"/> <figcaption> PSNR comparison against state-of-the-art JDD models on the Urban100/MIT moire datasets</figcaption> </figure> </p> <p>The results of this section are detailed in, <a href="https://arxiv.org/abs/2112.00913"><em>&quot;CDLNet: Noise-Adaptive Convolutional Dictionary Learning Network for Blind Denoising and Demosaicing&quot;</em></a>.</p> <p>See our <a href="/notes/cdlnet_supp">supplementary material</a> with animations of filters, thresholds, and sparse codes across layers.</p> <h2 id=gabor_is_enough ><a href="#gabor_is_enough" class=header-anchor >Gabor is Enough&#33;</a></h2> <figure style="text-align:center;"> <img src="/assets/dcdl/GDLNet.png" style="padding:0; width:100%" alt=" The GDLNet architecture with Mixture of Gabor filters."/> <figcaption> The GDLNet architecture with Mixture of Gabor filters.</figcaption> </figure> <p>Gabor filters &#40;Gaussian <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>×</mo></mrow><annotation encoding="application/x-tex">\times</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.66666em;vertical-align:-0.08333em;"></span><span class=mord >×</span></span></span></span> cosine&#41; have a long history neural networks. Cat eye-cells have been shown to have Gabor-like frequency responses, and the learned filters at the early stages of the AlexNet classifier are noted to be Gabor-like as well. We noticed that the trained filters of CDLNet also appear Gabor-like and wondered, &quot;Can Gabor-like be replaced with Gabor?&quot;. And so we parameterized <em>each and every</em> filter of CDLNet as a 2D real Gabor function, </p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>g</mi><mo stretchy=false >(</mo><mi mathvariant=bold >x</mi><mo separator=true >;</mo><mi>ϕ</mi><mo stretchy=false >)</mo><mo>=</mo><mi>α</mi><msup><mi>e</mi><mrow><mo>−</mo><mo stretchy=false >∥</mo><mi mathvariant=bold >a</mi><mo>∘</mo><mi mathvariant=bold >x</mi><msubsup><mo stretchy=false >∥</mo><mn>2</mn><mn>2</mn></msubsup></mrow></msup><mi>cos</mi><mo>⁡</mo><mo stretchy=false >(</mo><msubsup><mi mathvariant=bold >ω</mi><mn>0</mn><mi>T</mi></msubsup><mi mathvariant=bold >x</mi><mo>+</mo><mi>ψ</mi><mo stretchy=false >)</mo><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> g(\mathbf{x}; \phi) = \alpha e^{-\lVert \mathbf{a} \circ \mathbf{x} \rVert_2^2} \cos(\mathbf{\omega}_0^T \mathbf{x} + \psi), </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class=mopen >(</span><span class="mord mathbf">x</span><span class=mpunct >;</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal">ϕ</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1.2869199999999998em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class=mord ><span class="mord mathnormal">e</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:1.0369199999999998em;"><span style="top:-3.1130000000000004em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mopen mtight">∥</span><span class="mord mathbf mtight">a</span><span class="mbin mtight">∘</span><span class="mord mathbf mtight">x</span><span class="mclose mtight"><span class="mclose mtight">∥</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8913142857142857em;"><span style="top:-2.214em;margin-left:0em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span><span style="top:-2.931em;margin-right:0.07142857142857144em;"><span class=pstrut  style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.286em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mop >cos</span><span class=mopen >(</span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.8913309999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.247em;"><span></span></span></span></span></span></span><span class="mord mathbf">x</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222222222222222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span><span class=mclose >)</span><span class=mpunct >,</span></span></span></span></span> <p>with <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo>=</mo><mo stretchy=false >(</mo><mi>α</mi><mo separator=true >,</mo><mi mathvariant=bold >a</mi><mo separator=true >,</mo><msub><mi mathvariant=bold >ω</mi><mn>0</mn></msub><mo separator=true >,</mo><mi>ψ</mi><mo stretchy=false >)</mo><mo>∈</mo><msup><mi mathvariant=double-struck >R</mi><mn>6</mn></msup></mrow><annotation encoding="application/x-tex">\phi = (\alpha, \mathbf{a}, \mathbf{\omega}_0, \psi) \in \mathbb R^6</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="mord mathnormal">ϕ</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathbf">a</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.16666666666666666em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ψ</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span><span class=mrel >∈</span><span class=mspace  style="margin-right:0.2777777777777778em;"></span></span><span class=base ><span class=strut  style="height:0.8141079999999999em;vertical-align:0em;"></span><span class=mord ><span class="mord mathbb">R</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span> as learnable parameters. We also considered <em>mixture of Gabor</em> &#40;MoG&#41; filters, i.e. each filter as sum of Gabor filters. We call this network GDLNet. Surprisingly, with just MoG&#61;1, GDLNet can achieve competitive results with state-of-the-art CNN denoisers &#40;see table below&#41;.</p> <figure style="text-align:center;"> <img src="/assets/dcdl/gdlnet_table.png" style="padding:0; width:70%" alt=" PSNR comparison against grayscale denoisers on BSD68 testset."/> <figcaption> PSNR comparison against grayscale denoisers on BSD68 testset.</figcaption> </figure> <p>Our results suggest that the mechanisms behind low-level image processing neural networks need not be more complex than real Gabor filterbanks. Check out our preprint, <a href="https://arxiv.org/abs/2204.11146"><em>&quot;Gabor is Enough: Interpretable Deep Denoising with a Gabor Synthesis Dictionary Prior&quot;</em></a>, for more results and information.</p> <div class=page-foot > <div class=copyright > <!--<a href="https://github.com/nikopj">GitHub</a> <br> --> &copy; <a href="https://github.com/nikopj">Nikola Janjušević</a>. Last modified: 2022-10-05. Built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> + <a href="https://julialang.org">Julia</a>. </div> </div> </div>